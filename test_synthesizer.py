# test_synthesizer.py

import os
import json
from dotenv import load_dotenv
from agents.synthesizer_agent import SynthesizerAgent
from agents.codebook_repository import CodebookRepository
from agents.embedding_client import EmbeddingClient

def run_test():

    print("--- INICIANDO PRUEBA DEL SYNTHESIZER AGENT ---")
    
    # 1. Cargar configuraci√≥n
    load_dotenv()
    google_api_key = os.getenv("GOOGLE_API_KEY")
    if not google_api_key:
        raise ValueError("La variable de entorno google_api_key no est√° configurada. Aseg√∫rate de tener un archivo .env")

    # 2. Inyecci√≥n de Dependencias
    # Apuntaremos a un codebook de prueba para no afectar el real
    test_repo = CodebookRepository(codebook_path="data/codebook.TEST.json")
    client = EmbeddingClient(api_key=google_api_key)
    # Usamos un umbral de 0.85 para la prueba, puede ser m√°s estricto (0.90) en producci√≥n
    synthesizer = SynthesizerAgent(repository=test_repo, client=client, similarity_threshold=0.85)
    
    # 3. Datos de prueba: Leer desde el archivo generado por test_coder.py
    generated_codes_path = os.path.join("data", "generated_codes.jsonl")
    print(f"\nüìÑ Cargando c√≥digos generados desde '{generated_codes_path}'...")

    try:
        with open(generated_codes_path, 'r', encoding='utf-8') as f:
            # Leer todas las l√≠neas y parsear el JSON de cada una
            all_coded_insights = [json.loads(line) for line in f]
    except FileNotFoundError:
        print(f"‚ùå ERROR: El archivo '{generated_codes_path}' no fue encontrado.")
        print("‚û°Ô∏è  Aseg√∫rate de haber ejecutado 'test_coder.py' primero para generarlo.")
        return
    except json.JSONDecodeError:
        print(f"‚ùå ERROR: El archivo '{generated_codes_path}' contiene JSON inv√°lido.")
        return

    # Extraer todos los 'codigos_abiertos' en una √∫nica lista plana
    batch_de_nuevos_codigos = []
    for insight in all_coded_insights:
        codes = insight.get("codigos_abiertos")
        if codes and isinstance(codes, list):
            batch_de_nuevos_codigos.extend(codes)

    if not batch_de_nuevos_codigos:
        print("‚ö†Ô∏è No se encontraron c√≥digos para procesar en el archivo de entrada. Finalizando prueba.")
        return

    print(f"\nüß† Procesando lote de prueba con {len(batch_de_nuevos_codigos)} c√≥digos extra√≠dos del archivo.")

    # 4. Ejecuci√≥n
    translation_map = synthesizer.process_batch(batch_de_nuevos_codigos)
    
    print("\n--- RESULTADO DEL TRANSLATION MAP ---")
    print("C√≥digos originales ‚Üí IDs unificados:")
    for original_label, unified_id in translation_map.items():
        print(f"  '{original_label}' ‚Üí {unified_id}")
    
    print(f"\n--- RESUMEN ---")
    print(f"C√≥digos originales procesados: {len(batch_de_nuevos_codigos)}")
    print(f"C√≥digos √∫nicos despu√©s de unificaci√≥n: {len(set(translation_map.values()))}")
    print(f"Reducci√≥n: {len(batch_de_nuevos_codigos) - len(set(translation_map.values()))} c√≥digos unificados")
    
    print("\n--- PRUEBA FINALIZADA ---")
    print(f"Revisa el archivo 'data/codebook.TEST.json' para ver el resultado.")
    print(f"El translation map est√° listo para ser usado en la unificaci√≥n de resultados finales.")
    # Deber√≠as ver solo 2 c√≥digos √∫nicos al final, cada uno con un contador de 3.

if __name__ == "__main__":
    run_test()